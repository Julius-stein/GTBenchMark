out_dir: ./results/GraphormerArxiv
metric_agg: argmax
metric_best: accuracy
seed: 0
dataset:
  dir: /mnt/data2/duxin/.datasets
  format: OGB
  name: ogbn_arxiv
  task: node
  task_type: classification
  task_entity: item
  transductive: True
  node_encoder_num_types: 28
  edge_encoder_num_types: 4

posenc_GraphormerBias:
  enable: True
  node_degrees_only: False

  # —— DGL 中的 SpatialEncoder（最短路径距离，-1 表示不连通） ——  
  # DGL 里 shortest_dist 给出的 spd ∈ {-1,0,1,…}, 这里区分 0…19 + “-1” 共 20 类
  num_spatial_types: 5
  num_in_degrees: 64           # DGL 里 clamp(in_degrees+1, 0, 512) 后，每个 deg 索引到 0…63 的 embedding
  num_out_degrees: 64           # 同上，out_degree

  # —— DGL 中的 PathEncoder（多跳路径上的边特征） ——  
  enable_path_bias: True        # 打开 PathEncoder
  multi_hop_max_dist: 5         # DGL 里截/填 path 长度到 5 hops
  path_edge_feat_dim: 4         # bond 特征维度（4 种键合）
  use_graph_token: True

train:
  mode: custom
  sampler: neighbor
  neighbor_sizes: [10,15] 
  iter_per_epoch: -1
  batch_size: 64
  eval_period: 4
  ckpt_period: 100
  tqdm: True
  persistent_workers: True
  pin_memory: True
val:
  sampler: neighbor
  iter_per_epoch: -1
  tqdm: True
model:
  type: GTModel
  loss_fun: cross_entropy
gt:
  layers: 18
  attn_heads: 8
  dim_hidden: 1024
  dropout: 0.0
  attn_dropout: 0.1
  input_dropout: 0.1
  activation_dropout: 0.1
  ffn_dim: 1024
  #,GraphormerBias
  node_encoder_list: [TypeDictNode,GraphormerBias]
  edge_encoder_list: []
  encoder_type : cascade #cascade or concat
  attn_type: GeneralAttention
  layer_type: GraphTransformerLayer
  prepend_norm: True
  batch_norm: False
  layer_norm: True
  residual: True
  act : relu
  head: inductive_node
  # use_flex: True
  # flex_block_size: 19
gnn:
  dropout: 0.2
optim:
  batch_accumulation: 32
  clip_grad_norm: True
  optimizer: adamW
  weight_decay: 1e-5
  base_lr: 0.0005
  max_epoch: 5
  scheduler: polynomial_with_warmup
  num_warmup_epochs: 5

perf:
  mode: "off" 