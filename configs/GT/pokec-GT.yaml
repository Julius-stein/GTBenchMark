out_dir: ./results/arxiv
metric_agg: argmax
metric_best: accuracy
num_workers: 0
seed: 42
dataset:
  dir: /mnt/data2/duxin/.datasets
  format: OGB
  name: ogbn-arxiv
  split_mode: standard
  task: node
  task_type: classification
  task_entity: item
  transductive: true
  add_self_loops: True

metis:
  drop_rate: 0.0
  enable: true
  num_hops: 0
  online: true
  patch_num_diff: -1
  patch_rw_dim: 0
  patches: 3000
  mode: subgraph

train:
  enable_ckpt: false
  eval_period: 5
  mode: custom
  batch_size: 256
  tqdm: True
  sampler: full_batch
  persistent_workers: True
  pin_memory: True
val:
  sampler: full_batch
  iter_per_epoch: -1
  tqdm: True
model:
  type: GTModel
  loss_fun: cross_entropy
gt:
  attn_dropout: 0.11922231223024432
  batch_norm: false
  dim_hidden: 128
  dropout: 0.05747741345615445
  layer_norm: true
  layer_type: Transformer
  attn_type: GeneralAttention
  layers: 2
  n_heads: 8
  ffn_dim: 256
  head: node
  # head: cluster_node
  encoder_type : cascade
  node_encoder_list: [RawEncoder]
  edge_encoder_list: [DummyEdge]
  input_dropout: 0.1
  activation_dropout: 0.1
  prepend_norm: True
  act : relu

gnn:
  mode: "off"
  dropout: 0.2
optim:
  base_lr: 0.0009588557917457037
  clip_grad_norm: true
  max_epoch: 200
  num_warmup_epochs: 5
  optimizer: adamW
  clip_grad_norm_value: 0.4157799272483611
  scheduler: cosine_with_warmup
  weight_decay: 6.440860069088798e-06

perf:
  mode: "off" 
  include_regex: [] #！小写
  include_name: ["DummyEdgeEncoder","GeneralAttn","FFN_block"]